#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gpus=1
#SBATCH --job-name=Train
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=04:00:00
#SBATCH --output=output/dimensions_%A.out

module purge
module load 2024
module load Anaconda3/2024.06-1

source activate hyperbolic

export WANDB_API_KEY=868e3906005e2c816a758fcbc88d5098dabc27be
export PYTHONPATH=$(pwd)

# -------------------------
# Model configurations
# -------------------------

declare -A MODELS

MODELS[personal]="--model personal --num_heads 2 --patience 400 \
  --attn_scope adjs --lr 0.005 --head_fusion midpoint --optimizer RiemannianAdam \
  --curvature 1.0 --dropout 0.1 --wd 0.003 --reset_params kaiming"

MODELS[hypformer]="--model hypformer --num_heads 2 --patience 400 \
  --attn_scope adjs --lr 0.005 --optimizer RiemannianAdam \
  --curvature 1.0 --dropout 0.3 --wd 0.001"

MODELS[euclidean]="--model euclidean --num_heads 2 --patience 400 \
  --attn_scope adjs --lr 0.001 --optimizer Adam \
  --dropout 0.1 --wd 0.0001"

MODELS[euclidean_lorentz]="--model euclidean --lorentz_map --num_heads 2 --patience 400 \
  --attn_scope adjs --lr 0.003 --optimizer Adam \
  --dropout 0.1 --wd 0.0001"

# -------------------------
# Experiment sweep
# -------------------------

# pick dataset
DATASET="disease"

for MODEL in "${!MODELS[@]}"; do
  echo "=== Starting model: $MODEL ==="

  mkdir -p logs/$DATASET/$MODEL

  for DIM in 128 32 16 8; do
    LOGFILE="logs/${DATASET}/${MODEL}/dim_${DIM}.log"
    echo "=== Running model=$MODEL dim=$DIM ===" > "$LOGFILE"

    for SPLIT in {0..9}; do
      echo "=== Split $SPLIT ===" | tee -a "$LOGFILE"

      python main.py \
        --dataset $DATASET \
        --split $SPLIT \
        --epochs 500 \
        --log_every 50 \
        --hidden_dim $DIM \
        ${MODELS[$MODEL]} \
        >> "$LOGFILE" 2>&1

      echo "" >> "$LOGFILE"
    done
  done
done
